{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "from sklearn.metrics import accuracy_score\n",
    "import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from more_itertools import set_partitions\n",
    "import math\n",
    "import random\n",
    "from sklearn.utils import resample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file_path = 'Iris.csv'\n",
    "file_path = 'eye-color.data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(file_path, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = list(df.columns)\n",
    "headers.remove('class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Eye', 'Hair', 'Height']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DT:\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        :param k: Number of Clusters\n",
    "        :param max_it: Maximum number of iterations if hasn't reached convergence yet.\n",
    "        \"\"\"\n",
    "        self.data_column_names = None\n",
    "        self.feature_indices = None\n",
    "        self.forest = []\n",
    "        self.predictions = []\n",
    "        self.feature_importance = []\n",
    "        self.number_trees = None\n",
    "        self.number_features = None\n",
    "        self.num_cols = None\n",
    "        self.type_cols = None\n",
    "        \n",
    "    def make_and_test_forest(self,train_data,test_data,number_features=2,number_trees=2):\n",
    "        the_forest = self.plant_forest(train_data,number_features,number_trees)\n",
    "        accuracy,self.predictions,self.multiple_predictions = self.make_prediction_forest(the_forest,test_data)\n",
    "        if sum(self.feature_importance) != 0:\n",
    "            self.feature_importance = [x/sum(self.feature_importance) for x in self.feature_importance]\n",
    "        else:\n",
    "            self.feature_importance = [0]*len(self.feature_indices)\n",
    "        results = {'Accuracy': accuracy, 'F': self.number_features, 'NT': self.number_trees}\n",
    "        for i in range(len(self.feature_importance)):\n",
    "            results[self.data_column_names[i]] = self.feature_importance[i]\n",
    "        return results\n",
    "    \n",
    "    def plant_forest(self,train_data,number_features=2,number_trees=2):\n",
    "        self.forest = []\n",
    "        self.data_column_names = list(train_data.columns)\n",
    "        self.data_column_names.remove('class')\n",
    "        train_dataset = train_data.values\n",
    "        num_rows, num_cols = np.shape(train_dataset)\n",
    "        self.num_cols = num_cols -1\n",
    "        class_index = self.num_cols\n",
    "        self.feature_indices = list(range(class_index)) + list(range(class_index + 1, self.num_cols))\n",
    "        self.number_features = number_features\n",
    "        self.number_trees = number_trees\n",
    "        self.type_cols = list(train_data.dtypes)\n",
    "        self.feature_importance = [0]*len(self.feature_indices)\n",
    "  \n",
    "\n",
    "        for i in range(self.number_trees):\n",
    "            if self.number_features == 'uniform':\n",
    "                number_features = int(np.random.uniform(1,self.num_cols))\n",
    "                random_features = random.sample(self.feature_indices,number_features)\n",
    "            else:\n",
    "                random_features = random.sample(self.feature_indices,self.number_features)\n",
    "            the_tree = self.plant_tree(train_data,random_features)\n",
    "            self.forest.append(the_tree)\n",
    "\n",
    "        return self.forest        \n",
    "        \n",
    "    def plant_tree(self,train_data, random_features):\n",
    "        ''' start the process of recursion on the training data and let the tree\n",
    "        grow to its max depth using subset of random features'''\n",
    "\n",
    "        #get column names minus class\n",
    "        #choose random set of features from column names\n",
    "\n",
    "        root_node = self.find_best_split_point(train_data,random_features)\n",
    "        self.recursive_splitter(root_node,random_features)\n",
    "        return root_node\n",
    "    def build_split(self,data,column_to_split,split_values):\n",
    "        '''build 2 groups of data by splitting data on the column_to_split \n",
    "           at the split_value'''\n",
    "        left_split = data.loc[data[self.data_column_names[column_to_split]].isin(split_values[0])]\n",
    "        right_split = data.loc[data[self.data_column_names[column_to_split]].isin(split_values[1])]\n",
    "\n",
    "        return left_split,right_split\n",
    "\n",
    "    def build_split_numeric(self,data,column_to_split,split_value):\n",
    "        '''build 2 groups of data by splitting data on the column_to_split \n",
    "           at the split_value'''\n",
    "        left_split = data[data[column_to_split]<split_value]\n",
    "        right_split = data[data[column_to_split]>=split_value]\n",
    "\n",
    "        return left_split,right_split\n",
    "\n",
    "    def multi_gini_index(self,group1,group2):\n",
    "        '''Calculate Gini Impurity, func expects to be passed \n",
    "           the 2 groups of data that are the result of a split'''\n",
    "        class_proportions_group1 = group1['class'].value_counts(normalize=True)    \n",
    "        class_proportions_group2 = group2['class'].value_counts(normalize=True)    \n",
    "\n",
    "        instance_proportion_group1 = len(group1)/(len(group1)+len(group2))\n",
    "        instance_proportion_group2 = len(group2)/(len(group1)+len(group2))\n",
    "\n",
    "        gini1 = (1 - class_proportions_group1.pow(2).sum())*(instance_proportion_group1)\n",
    "        gini2 = (1 - class_proportions_group2.pow(2).sum())*(instance_proportion_group2)\n",
    "        gini = gini1+gini2\n",
    "\n",
    "        return gini\n",
    "\n",
    "    def single_gini_index(self,group):\n",
    "        '''Calculate Gini Impurity of a single group'''\n",
    "        class_proportions = group['class'].value_counts(normalize=True)    \n",
    "\n",
    "        gini = (1 - class_proportions.pow(2).sum())\n",
    "\n",
    "        return gini\n",
    "\n",
    "    def find_best_split_point(self,passed_data, feature_subset):\n",
    "        '''find best split point iterating over range of values returned from the \n",
    "        get_range_to_split_on function and return a dictionary which functions as a node '''\n",
    "        print(feature_subset)\n",
    "        best_split_gini = 10\n",
    "        attribute_index = None\n",
    "        best_split_value = None\n",
    "        best_split_groups  = None\n",
    "        best_split_column = None\n",
    "        best_split_type = None\n",
    "        \n",
    "        gini_X = self.single_gini_index(passed_data)\n",
    "        for attribute_index in feature_subset:\n",
    "            if self.type_cols[attribute_index] == 'O':\n",
    "                attribute_values = list(set([x[attribute_index] for x in passed_data.values]))\n",
    "                if len(attribute_values) == 1:\n",
    "                    gini_XA = self.single_gini_index(passed_data)\n",
    "                    if gini_XA < best_split_gini:\n",
    "                        best_split_gini = gini_XA\n",
    "                        best_split_column  = attribute_index\n",
    "                        best_split_value = attribute_values\n",
    "                        best_split_groups = passed_data, pd.DataFrame(columns = passed_data.columns)\n",
    "                        best_split_type = 0\n",
    "                else:    \n",
    "                    partitions = list(set_partitions(attribute_values, 2))\n",
    "                    for part in partitions:\n",
    "                        if len(part[1]) < len(part[0]):\n",
    "                            part = [part[1], part[0]]    \n",
    "                        left_split, right_split = self.build_split(passed_data, attribute_index, part)\n",
    "                        gini_XA =  self.multi_gini_index(left_split, right_split)\n",
    "                        if gini_XA < best_split_gini:\n",
    "                            best_split_gini = gini_XA\n",
    "                            best_split_column  = attribute_index\n",
    "                            best_split_value = part\n",
    "                            best_split_groups = left_split, right_split\n",
    "                            best_split_type = 0\n",
    "            else:\n",
    "                col_name = passed_data.columns[attribute_index]\n",
    "                split_point = float(passed_data[col_name].median())\n",
    "                left_split, right_split = self.build_split_numeric(passed_data,col_name,split_point)\n",
    "                gini_XA = self.multi_gini_index(left_split, right_split)\n",
    "\n",
    "                if gini_XA < best_split_gini:\n",
    "                    best_split_gini = gini_XA\n",
    "                    best_split_column = attribute_index\n",
    "                    best_split_value = split_point\n",
    "                    best_split_groups = left_split, right_split\n",
    "                    best_split_type = 1\n",
    "        \n",
    "        gini_A = gini_X - best_split_gini\n",
    "        self.feature_importance[best_split_column] += gini_A\n",
    "        return {'column_id': best_split_column,'column_name':self.data_column_names[best_split_column],'type':best_split_type,'dsplit_value':best_split_value,\n",
    "                     'gini':best_split_gini, 'groups': best_split_groups}\n",
    "\n",
    "    def recursive_splitter(self,node,random_features):\n",
    "        '''this function recursively splits the data starting with the root node which its passed\n",
    "        untill the groups are homogenous or further splits result in empty nodes'''\n",
    "        left_group,right_group = node['groups']\n",
    "        #delete the groups entry in original node\n",
    "        del node['groups']\n",
    "        #check if the groups of the node are empty\n",
    "        if left_group.empty or right_group.empty:\n",
    "            #combine as we will use original to predict\n",
    "            combined = pd.concat([left_group,right_group])\n",
    "            predicted_class = combined['class'].value_counts().index[0]\n",
    "            node['left']=node['right']=predicted_class\n",
    "            return [predicted_class]\n",
    "        #check if the groups of the node are homogenous otherwise call recursive_spltter again\n",
    "        if self.single_gini_index(left_group) == 0:\n",
    "            predicted_class = left_group['class'].value_counts().index[0]\n",
    "            node['left'] = predicted_class\n",
    "        else:\n",
    "            node['left'] = self.find_best_split_point(left_group,random_features)\n",
    "            curr_node = self.recursive_splitter(node['left'],random_features)\n",
    "            if type(curr_node) == list:\n",
    "                node['left'] = curr_node[0]\n",
    "\n",
    "        if self.single_gini_index(right_group) == 0:\n",
    "            predicted_class = right_group['class'].value_counts().index[0]\n",
    "            node['right'] = predicted_class\n",
    "        else:\n",
    "            node['right'] = self.find_best_split_point(right_group,random_features)\n",
    "            curr_node = self.recursive_splitter(node['right'],random_features)\n",
    "            if type(curr_node) == list:\n",
    "                node['right'] = curr_node[0]        \n",
    "        return node\n",
    "\n",
    "    def make_prediction_tree(self,data_row,root_node):\n",
    "        '''recursively traverse the tree from root to leaf turning left if feature value\n",
    "        to test is less than dsplit_value or right otherwise until we reach a leaf node'''\n",
    "\n",
    "        if  root_node['type'] == 0:\n",
    "            #check if feature of data_row is less than dsplit_value else move to right branch\n",
    "            if data_row[root_node['column_id']] in root_node['dsplit_value'][0]:\n",
    "                #check if at a branch or a leaf if branch recursively call predict else return leaf prediction\n",
    "                if type(root_node['left']) is dict:\n",
    "                    return self.make_prediction_tree(data_row,root_node['left'])\n",
    "                else:\n",
    "                    return root_node['left']\n",
    "            else:\n",
    "                if type(root_node['right']) is dict:\n",
    "                    return self.make_prediction_tree(data_row,root_node['right'])\n",
    "                else:\n",
    "                    return root_node['right']\n",
    "        else:\n",
    "            if data_row[root_node['column_id']] < root_node['dsplit_value']:\n",
    "                #check if at a branch or a leaf if branch recursively call predict else return leaf prediction\n",
    "                if type(root_node['left']) is dict:\n",
    "                    return self.make_prediction_tree(data_row,root_node['left'])\n",
    "                else:\n",
    "                    return root_node['left']\n",
    "            else:\n",
    "                if type(root_node['right']) is dict:\n",
    "                    return self.make_prediction_tree(data_row,root_node['right'])\n",
    "                else:\n",
    "                    return root_node['right']\n",
    "\n",
    "    def make_prediction_forest(self,forest,test_data):\n",
    "\n",
    "        classes = test_data['class']\n",
    "        classes = classes.reset_index(drop=True)\n",
    "\n",
    "        forest_predictions = []\n",
    "        multiple_forest_predictions = []\n",
    "        for index,row in test_data.iterrows():\n",
    "            tree_predictions = []\n",
    "            for tree in forest:\n",
    "                tree_predictions.append(self.make_prediction_tree(row,tree))\n",
    "            multiple_forest_predictions.append(tree_predictions)\n",
    "            tree_predictions_series = pd.Series(tree_predictions)\n",
    "            predicted_class = tree_predictions_series.value_counts().index[0]    \n",
    "            forest_predictions.append(predicted_class)\n",
    "\n",
    "        forest_pred_series = pd.Series(forest_predictions)\n",
    "\n",
    "        results = forest_pred_series==classes\n",
    "\n",
    "        successes = 0\n",
    "\n",
    "        for i in results:\n",
    "            if i==True: successes+=1\n",
    "\n",
    "        accuracy = successes/len(classes)     \n",
    "\n",
    "\n",
    "        return accuracy,forest_pred_series, multiple_forest_predictions\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RDT(DT):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "    \n",
    "    def plant_forest(self,train_data,number_features=2,number_trees=2):\n",
    "        self.forest = []\n",
    "        self.data_column_names = list(train_data.columns)\n",
    "        self.data_column_names.remove('class')\n",
    "        train_dataset = train_data.values\n",
    "        num_rows, num_cols = np.shape(train_dataset)\n",
    "        self.num_cols = num_cols -1\n",
    "        class_index = self.num_cols\n",
    "        self.feature_indices = list(range(class_index)) + list(range(class_index + 1, self.num_cols))\n",
    "        self.number_features = number_features\n",
    "        self.number_trees = number_trees\n",
    "        self.type_cols = list(train_data.dtypes)\n",
    "        self.feature_importance = [0]*len(self.feature_indices)\n",
    "  \n",
    "        #resample training data for bagging\n",
    "        resampled_training_sets = []\n",
    "        for i in range(self.number_trees):\n",
    "            dataset = resample(train_data, replace=True)\n",
    "            #dataset = train_data.sample(frac=fraction_samples,replace=True)\n",
    "            resampled_training_sets.append(dataset) \n",
    "        for dataset in resampled_training_sets:\n",
    "            the_tree = self.plant_tree(train_data)\n",
    "            self.forest.append(the_tree)\n",
    "\n",
    "        return self.forest        \n",
    "        \n",
    "    def plant_tree(self,train_data):\n",
    "        ''' start the process of recursion on the training data and let the tree\n",
    "        grow to its max depth using subset of random features'''\n",
    "\n",
    "        #get column names minus class\n",
    "        #choose random set of features from column names\n",
    "        random_features = random.sample(self.feature_indices,self.number_features)\n",
    "        root_node = self.find_best_split_point(train_data,random_features)\n",
    "        self.recursive_splitter(root_node)\n",
    "        return root_node\n",
    "\n",
    "\n",
    "    def recursive_splitter(self,node):\n",
    "        '''this function recursively splits the data starting with the root node which its passed\n",
    "        untill the groups are homogenous or further splits result in empty nodes'''\n",
    "        random_features = random.sample(self.feature_indices,self.number_features)\n",
    "        left_group,right_group = node['groups']\n",
    "        #delete the groups entry in original node\n",
    "        del node['groups']\n",
    "        #check if the groups of the node are empty\n",
    "        if left_group.empty or right_group.empty:\n",
    "            #combine as we will use original to predict\n",
    "            combined = pd.concat([left_group,right_group])\n",
    "            predicted_class = combined['class'].value_counts().index[0]\n",
    "            node['left']=node['right']=predicted_class\n",
    "            return [predicted_class]\n",
    "        #check if the groups of the node are homogenous otherwise call recursive_spltter again\n",
    "        if self.single_gini_index(left_group) == 0:\n",
    "            predicted_class = left_group['class'].value_counts().index[0]\n",
    "            node['left'] = predicted_class\n",
    "        else:\n",
    "            node['left'] = self.find_best_split_point(left_group,random_features)\n",
    "            curr_node = self.recursive_splitter(node['left'])\n",
    "            if type(curr_node) == list:\n",
    "                node['left'] = curr_node[0]\n",
    "\n",
    "        if self.single_gini_index(right_group) == 0:\n",
    "            predicted_class = right_group['class'].value_counts().index[0]\n",
    "            node['right'] = predicted_class\n",
    "        else:\n",
    "            node['right'] = self.find_best_split_point(right_group,random_features)\n",
    "            curr_node = self.recursive_splitter(node['right'])\n",
    "            if type(curr_node) == list:\n",
    "                node['right'] = curr_node[0]        \n",
    "        return node\n",
    "\n",
    "    def make_prediction_tree(self,data_row,root_node):\n",
    "        '''recursively traverse the tree from root to leaf turning left if feature value\n",
    "        to test is less than dsplit_value or right otherwise until we reach a leaf node'''\n",
    "\n",
    "        if  root_node['type'] == 0:\n",
    "            #check if feature of data_row is less than dsplit_value else move to right branch\n",
    "            if data_row[root_node['column_id']] in root_node['dsplit_value'][0]:\n",
    "                #check if at a branch or a leaf if branch recursively call predict else return leaf prediction\n",
    "                if type(root_node['left']) is dict:\n",
    "                    return self.make_prediction_tree(data_row,root_node['left'])\n",
    "                else:\n",
    "                    return root_node['left']\n",
    "            else:\n",
    "                if type(root_node['right']) is dict:\n",
    "                    return self.make_prediction_tree(data_row,root_node['right'])\n",
    "                else:\n",
    "                    return root_node['right']\n",
    "        else:\n",
    "            if data_row[root_node['column_id']] < root_node['dsplit_value']:\n",
    "                #check if at a branch or a leaf if branch recursively call predict else return leaf prediction\n",
    "                if type(root_node['left']) is dict:\n",
    "                    return self.make_prediction_tree(data_row,root_node['left'])\n",
    "                else:\n",
    "                    return root_node['left']\n",
    "            else:\n",
    "                if type(root_node['right']) is dict:\n",
    "                    return self.make_prediction_tree(data_row,root_node['right'])\n",
    "                else:\n",
    "                    return root_node['right']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'headers' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-ec79b271113e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_results\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Accuracy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'F'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'NT'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'headers' is not defined"
     ]
    }
   ],
   "source": [
    "df_results = pd.DataFrame(columns=['Accuracy', 'F', 'NT'] + headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Eye</th>\n",
       "      <th>Hair</th>\n",
       "      <th>Height</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Blue</td>\n",
       "      <td>Blonde</td>\n",
       "      <td>Tall</td>\n",
       "      <td>C+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Blue</td>\n",
       "      <td>Brown</td>\n",
       "      <td>Medium</td>\n",
       "      <td>C+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Brown</td>\n",
       "      <td>Brown</td>\n",
       "      <td>Medium</td>\n",
       "      <td>C-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Green</td>\n",
       "      <td>Brown</td>\n",
       "      <td>Medium</td>\n",
       "      <td>C-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Green</td>\n",
       "      <td>Brown</td>\n",
       "      <td>Tall</td>\n",
       "      <td>C+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Brown</td>\n",
       "      <td>Brown</td>\n",
       "      <td>Low</td>\n",
       "      <td>C-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Green</td>\n",
       "      <td>Blonde</td>\n",
       "      <td>Low</td>\n",
       "      <td>C-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Blue</td>\n",
       "      <td>Brown</td>\n",
       "      <td>Medium</td>\n",
       "      <td>C+</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Eye    Hair  Height class\n",
       "0   Blue  Blonde    Tall    C+\n",
       "1   Blue   Brown  Medium    C+\n",
       "2  Brown   Brown  Medium    C-\n",
       "3  Green   Brown  Medium    C-\n",
       "4  Green   Brown    Tall    C+\n",
       "5  Brown   Brown     Low    C-\n",
       "6  Green  Blonde     Low    C-\n",
       "7   Blue   Brown  Medium    C+"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = DT()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1, 0]\n",
      "[1, 0]\n",
      "[1, 0]\n",
      "[1, 0]\n"
     ]
    }
   ],
   "source": [
    "forest_results = rf.make_and_test_forest(df,df,number_features='uniform',number_trees=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Accuracy': 1.0,\n",
       " 'F': 2,\n",
       " 'NT': 1,\n",
       " 'Eye': 0.4428969359331476,\n",
       " 'Hair': 0.0,\n",
       " 'Height': 0.5571030640668524}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'column_id': 1,\n",
       "  'column_name': 'Hair',\n",
       "  'type': 0,\n",
       "  'dsplit_value': [['Blonde'], ['Brown']],\n",
       "  'gini': 0.5,\n",
       "  'left': 'C-',\n",
       "  'right': 'C-'},\n",
       " {'column_id': 1,\n",
       "  'column_name': 'Hair',\n",
       "  'type': 0,\n",
       "  'dsplit_value': [['Blonde'], ['Brown']],\n",
       "  'gini': 0.5,\n",
       "  'left': 'C-',\n",
       "  'right': 'C-'},\n",
       " {'column_id': 0,\n",
       "  'column_name': 'Eye',\n",
       "  'type': 0,\n",
       "  'dsplit_value': [['Blue'], ['Green', 'Brown']],\n",
       "  'gini': 0.1999999999999999,\n",
       "  'left': 'C+',\n",
       "  'right': {'column_id': 0,\n",
       "   'column_name': 'Eye',\n",
       "   'type': 0,\n",
       "   'dsplit_value': [['Green'], ['Brown']],\n",
       "   'gini': 0.26666666666666666,\n",
       "   'left': {'column_id': 1,\n",
       "    'column_name': 'Hair',\n",
       "    'type': 0,\n",
       "    'dsplit_value': [['Blonde'], ['Brown']],\n",
       "    'gini': 0.3333333333333333,\n",
       "    'left': 'C-',\n",
       "    'right': 'C-'},\n",
       "   'right': 'C-'}}]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Accuracy': 1.0,\n",
       " 'F': 2,\n",
       " 'NT': 5,\n",
       " 'Eye': 0.45034788108791907,\n",
       " 'Hair': 0.03162555344718533,\n",
       " 'Height': 0.5180265654648957}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class RDT(DT):\n",
    "    def __init__(self, **kwargs):\n",
    "        \"\"\"\n",
    "        :param k: Number of Clusters\n",
    "        :param max_it: Maximum number of iterations if hasn't reached convergence yet.\n",
    "        \"\"\"\n",
    "        self.data_column_names = None\n",
    "        self.feature_indices = None\n",
    "        self.forest = []\n",
    "        self.predictions = []\n",
    "        self.feature_importance = []\n",
    "        self.number_trees = None\n",
    "        self.number_features = None\n",
    "        self.num_cols = None\n",
    "        self.type_cols = None\n",
    "        \n",
    "    def make_and_test_forest(self,train_data,test_data,number_features,number_trees=50,fraction_samples=1):\n",
    "        the_forest = self.plant_forest(train_data,number_features,number_trees,fraction_samples)\n",
    "        accuracy,self.predictions,self.multiple_predictions = self.make_prediction_forest(the_forest,test_data)\n",
    "        self.feature_importance = [x/sum(self.feature_importance) for x in self.feature_importance]\n",
    "        results = {'Accuracy': accuracy, 'F': self.number_features, 'NT': self.number_trees}\n",
    "        for i in range(len(self.feature_importance)):\n",
    "            results[self.data_column_names[i]] = self.feature_importance[i]\n",
    "        return results\n",
    "    \n",
    "    def plant_forest(self,train_data,number_features=2,number_trees=2,fraction_samples=1):\n",
    "        self.forest = []\n",
    "        self.data_column_names = list(train_data.columns)\n",
    "        self.data_column_names.remove('class')\n",
    "        train_dataset = train_data.values\n",
    "        num_rows, num_cols = np.shape(train_dataset)\n",
    "        self.num_cols = num_cols -1\n",
    "        class_index = self.num_cols\n",
    "        self.feature_indices = list(range(class_index)) + list(range(class_index + 1, self.num_cols))\n",
    "        self.number_features = number_features\n",
    "        self.number_trees = number_trees\n",
    "        self.type_cols = list(train_data.dtypes)\n",
    "        self.feature_importance = [0]*len(self.feature_indices)\n",
    "  \n",
    "        #resample training data for bagging\n",
    "        resampled_training_sets = []\n",
    "        for i in range(self.number_trees):\n",
    "            dataset = resample(train_data, replace=True)\n",
    "            #dataset = train_data.sample(frac=fraction_samples,replace=True)\n",
    "            resampled_training_sets.append(dataset) \n",
    "        for dataset in resampled_training_sets:\n",
    "            the_tree = self.plant_tree(train_data)\n",
    "            self.forest.append(the_tree)\n",
    "\n",
    "        return self.forest        \n",
    "        \n",
    "    def plant_tree(self,train_data):\n",
    "        ''' start the process of recursion on the training data and let the tree\n",
    "        grow to its max depth using subset of random features'''\n",
    "\n",
    "        #get column names minus class\n",
    "        #choose random set of features from column names\n",
    "        random_features = random.sample(self.feature_indices,self.number_features)\n",
    "        root_node = self.find_best_split_point(train_data,random_features)\n",
    "        self.recursive_splitter(root_node)\n",
    "        return root_node\n",
    "    def build_split(self,data,column_to_split,split_values):\n",
    "        '''build 2 groups of data by splitting data on the column_to_split \n",
    "           at the split_value'''\n",
    "        left_split = data.loc[data[self.data_column_names[column_to_split]].isin(split_values[0])]\n",
    "        right_split = data.loc[data[self.data_column_names[column_to_split]].isin(split_values[1])]\n",
    "\n",
    "        return left_split,right_split\n",
    "\n",
    "    def build_split_numeric(self,data,column_to_split,split_value):\n",
    "        '''build 2 groups of data by splitting data on the column_to_split \n",
    "           at the split_value'''\n",
    "        left_split = data[data[column_to_split]<split_value]\n",
    "        right_split = data[data[column_to_split]>=split_value]\n",
    "\n",
    "        return left_split,right_split\n",
    "\n",
    "    def multi_gini_index(self,group1,group2):\n",
    "        '''Calculate Gini Impurity, func expects to be passed \n",
    "           the 2 groups of data that are the result of a split'''\n",
    "        class_proportions_group1 = group1['class'].value_counts(normalize=True)    \n",
    "        class_proportions_group2 = group2['class'].value_counts(normalize=True)    \n",
    "\n",
    "        instance_proportion_group1 = len(group1)/(len(group1)+len(group2))\n",
    "        instance_proportion_group2 = len(group2)/(len(group1)+len(group2))\n",
    "\n",
    "        gini1 = (1 - class_proportions_group1.pow(2).sum())*(instance_proportion_group1)\n",
    "        gini2 = (1 - class_proportions_group2.pow(2).sum())*(instance_proportion_group2)\n",
    "        gini = gini1+gini2\n",
    "\n",
    "        return gini\n",
    "\n",
    "    def single_gini_index(self,group):\n",
    "        '''Calculate Gini Impurity of a single group'''\n",
    "        class_proportions = group['class'].value_counts(normalize=True)    \n",
    "\n",
    "        gini = (1 - class_proportions.pow(2).sum())\n",
    "\n",
    "        return gini\n",
    "\n",
    "    def find_best_split_point(self,passed_data, feature_subset):\n",
    "        '''find best split point iterating over range of values returned from the \n",
    "        get_range_to_split_on function and return a dictionary which functions as a node '''\n",
    "\n",
    "        best_split_gini = 10\n",
    "        attribute_index = None\n",
    "        best_split_value = None\n",
    "        best_split_groups  = None\n",
    "        best_split_column = None\n",
    "        best_split_type = None\n",
    "        \n",
    "        gini_X = self.single_gini_index(passed_data)\n",
    "        for attribute_index in feature_subset:\n",
    "            if self.type_cols[attribute_index] == 'O':\n",
    "                attribute_values = list(set([x[attribute_index] for x in passed_data.values]))\n",
    "                if len(attribute_values) == 1:\n",
    "                    gini_XA = self.single_gini_index(passed_data)\n",
    "                    if gini_XA < best_split_gini:\n",
    "                        best_split_gini = gini_XA\n",
    "                        best_split_column  = attribute_index\n",
    "                        best_split_value = attribute_values\n",
    "                        best_split_groups = passed_data, pd.DataFrame(columns = passed_data.columns)\n",
    "                        best_split_type = 0\n",
    "                else:    \n",
    "                    partitions = list(set_partitions(attribute_values, 2))\n",
    "                    for part in partitions:\n",
    "                        if len(part[1]) < len(part[0]):\n",
    "                            part = [part[1], part[0]]    \n",
    "                        left_split, right_split = self.build_split(passed_data, attribute_index, part)\n",
    "                        gini_XA =  self.multi_gini_index(left_split, right_split)\n",
    "                        if gini_XA < best_split_gini:\n",
    "                            best_split_gini = gini_XA\n",
    "                            best_split_column  = attribute_index\n",
    "                            best_split_value = part\n",
    "                            best_split_groups = left_split, right_split\n",
    "                            best_split_type = 0\n",
    "            else:\n",
    "                col_name = passed_data.columns[attribute_index]\n",
    "                split_point = float(passed_data[col_name].median())\n",
    "                left_split, right_split = self.build_split_numeric(passed_data,col_name,split_point)\n",
    "                gini_XA = self.multi_gini_index(left_split, right_split)\n",
    "\n",
    "                if gini_XA < best_split_gini:\n",
    "                    best_split_gini = gini_XA\n",
    "                    best_split_column = attribute_index\n",
    "                    best_split_value = split_point\n",
    "                    best_split_groups = left_split, right_split\n",
    "                    best_split_type = 1\n",
    "        \n",
    "        gini_A = gini_X - best_split_gini\n",
    "        self.feature_importance[best_split_column] += gini_A\n",
    "        return {'column_id': best_split_column,'column_name':self.data_column_names[best_split_column],'type':best_split_type,'dsplit_value':best_split_value,\n",
    "                     'gini':best_split_gini, 'groups': best_split_groups}\n",
    "\n",
    "    def recursive_splitter(self,node):\n",
    "        '''this function recursively splits the data starting with the root node which its passed\n",
    "        untill the groups are homogenous or further splits result in empty nodes'''\n",
    "        random_features = random.sample(self.feature_indices,self.number_features)\n",
    "        print(random_features)\n",
    "        left_group,right_group = node['groups']\n",
    "        #delete the groups entry in original node\n",
    "        del node['groups']\n",
    "        #check if the groups of the node are empty\n",
    "        if left_group.empty or right_group.empty:\n",
    "            #combine as we will use original to predict\n",
    "            combined = pd.concat([left_group,right_group])\n",
    "            predicted_class = combined['class'].value_counts().index[0]\n",
    "            node['left']=node['right']=predicted_class\n",
    "            return [predicted_class]\n",
    "        #check if the groups of the node are homogenous otherwise call recursive_spltter again\n",
    "        if self.single_gini_index(left_group) == 0:\n",
    "            predicted_class = left_group['class'].value_counts().index[0]\n",
    "            node['left'] = predicted_class\n",
    "        else:\n",
    "            node['left'] = self.find_best_split_point(left_group,random_features)\n",
    "            curr_node = self.recursive_splitter(node['left'])\n",
    "            if type(curr_node) == list:\n",
    "                node['left'] = curr_node[0]\n",
    "\n",
    "        if self.single_gini_index(right_group) == 0:\n",
    "            predicted_class = right_group['class'].value_counts().index[0]\n",
    "            node['right'] = predicted_class\n",
    "        else:\n",
    "            node['right'] = self.find_best_split_point(right_group,random_features)\n",
    "            curr_node = self.recursive_splitter(node['right'])\n",
    "            if type(curr_node) == list:\n",
    "                node['right'] = curr_node[0]        \n",
    "        return node\n",
    "\n",
    "    def make_prediction_tree(self,data_row,root_node):\n",
    "        '''recursively traverse the tree from root to leaf turning left if feature value\n",
    "        to test is less than dsplit_value or right otherwise until we reach a leaf node'''\n",
    "\n",
    "        if  root_node['type'] == 0:\n",
    "            #check if feature of data_row is less than dsplit_value else move to right branch\n",
    "            if data_row[root_node['column_id']] in root_node['dsplit_value'][0]:\n",
    "                #check if at a branch or a leaf if branch recursively call predict else return leaf prediction\n",
    "                if type(root_node['left']) is dict:\n",
    "                    return self.make_prediction_tree(data_row,root_node['left'])\n",
    "                else:\n",
    "                    return root_node['left']\n",
    "            else:\n",
    "                if type(root_node['right']) is dict:\n",
    "                    return self.make_prediction_tree(data_row,root_node['right'])\n",
    "                else:\n",
    "                    return root_node['right']\n",
    "        else:\n",
    "            if data_row[root_node['column_id']] < root_node['dsplit_value']:\n",
    "                #check if at a branch or a leaf if branch recursively call predict else return leaf prediction\n",
    "                if type(root_node['left']) is dict:\n",
    "                    return self.make_prediction_tree(data_row,root_node['left'])\n",
    "                else:\n",
    "                    return root_node['left']\n",
    "            else:\n",
    "                if type(root_node['right']) is dict:\n",
    "                    return self.make_prediction_tree(data_row,root_node['right'])\n",
    "                else:\n",
    "                    return root_node['right']\n",
    "\n",
    "    def make_prediction_forest(self,forest,test_data):\n",
    "\n",
    "        classes = test_data['class']\n",
    "        classes = classes.reset_index(drop=True)\n",
    "\n",
    "        forest_predictions = []\n",
    "        multiple_forest_predictions = []\n",
    "        for index,row in test_data.iterrows():\n",
    "            tree_predictions = []\n",
    "            for tree in forest:\n",
    "                tree_predictions.append(self.make_prediction_tree(row,tree))\n",
    "            multiple_forest_predictions.append(tree_predictions)\n",
    "            tree_predictions_series = pd.Series(tree_predictions)\n",
    "            predicted_class = tree_predictions_series.value_counts().index[0]    \n",
    "            forest_predictions.append(predicted_class)\n",
    "\n",
    "        forest_pred_series = pd.Series(forest_predictions)\n",
    "\n",
    "        results = forest_pred_series==classes\n",
    "\n",
    "        successes = 0\n",
    "\n",
    "        for i in results:\n",
    "            if i==True: successes+=1\n",
    "\n",
    "        accuracy = successes/len(classes)     \n",
    "\n",
    "\n",
    "        return accuracy,forest_pred_series, multiple_forest_predictions\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = df_results.append(forest_results, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F</th>\n",
       "      <th>NT</th>\n",
       "      <th>Eye</th>\n",
       "      <th>Hair</th>\n",
       "      <th>Height</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.483871</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.516129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.875</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.760766</td>\n",
       "      <td>0.239234</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.875</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.760766</td>\n",
       "      <td>0.239234</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.750</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy    F   NT       Eye      Hair    Height\n",
       "0     1.000  2.0  1.0  0.483871  0.000000  0.516129\n",
       "1     0.875  2.0  1.0  0.760766  0.239234  0.000000\n",
       "2     0.875  2.0  1.0  0.760766  0.239234  0.000000\n",
       "3     0.750  2.0  1.0  0.000000  0.000000  1.000000"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results.to_csv('eye_dt.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
